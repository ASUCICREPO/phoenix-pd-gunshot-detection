{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import schedule\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import six\n",
    "import tensorflow.keras as keras\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from datetime import timedelta as td\n",
    "from queue import Queue\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import backend as K\n",
    "from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FORMAT = pyaudio.paFloat32\n",
    "AUDIO_RATE = 44100\n",
    "NUMBER_OF_AUDIO_CHANNELS = 1\n",
    "AUDIO_DEVICE_INDEX = 6\n",
    "NUMBER_OF_FRAMES_PER_BUFFER = 4410\n",
    "SAMPLE_DURATION = 2\n",
    "AUDIO_VOLUME_THRESHOLD = 0.2\n",
    "NOISE_REDUCTION_ENABLED = False\n",
    "MODEL_CONFIDENCE_THRESHOLD = 0.5\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = AUDIO_RATE // 2\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "SMS_ALERTS_ENABLED = False\n",
    "ALERT_MESSAGE = \"ALERT: A Gunshot Was Detected on \"\n",
    "NETWORK_COVERAGE_TIMEOUT = 3600\n",
    "DESIGNATED_ALERT_RECIPIENTS = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
    "SCHEDULED_LOG_FILE_TRUNCATION_TIME = \"00:00\"\n",
    "sound_data = np.zeros(0, dtype = \"float32\")\n",
    "noise_sample_captured = False\n",
    "gunshot_sound_counter = 1\n",
    "noise_sample = []\n",
    "audio_analysis_queue = Queue()\n",
    "sms_alert_queue = Queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"~/Datasets/augmented_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == \"gun_shot\" else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa Wrapper Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Noise Reduction Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        verbose: Whether to display time statistics for the noise reduction process\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds = time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 1D Sound Arrays into Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=AUDIO_RATE,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV File Composition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a two-second gunshot sample as a WAV file\n",
    "def create_gunshot_wav_file(microphone_data, index, timestamp):\n",
    "    librosa.output.write_wav(\"~/Gunshot Detection System Recordings/Gunshot Sound Sample #\"\n",
    "                            + str(index) + \" (\"\n",
    "                            + str(timestamp) + \").wav\", microphone_data, 22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log File Truncation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_log_file():\n",
    "    with open(\"output.log\", 'w'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads 44100 x 1 Keras model from H5 file\n",
    "interpreter_1 = tf.lite.Interpreter(model_path = \"~/Models/1D.tflite\")\n",
    "interpreter_1.allocate_tensors()\n",
    "    \n",
    "# Sets the input shape for the 44100 x 1 model\n",
    "input_details_1 = interpreter_1.get_input_details()\n",
    "output_details_1 = interpreter_1.get_output_details()\n",
    "input_shape_1 = input_details_1[0]['shape']\n",
    "\n",
    "# Loads 128 x 64 Keras model from H5 file\n",
    "interpreter_2 = tf.lite.Interpreter(model_path = \"~/Models/128_x_64_2D.tflite\")\n",
    "interpreter_2.allocate_tensors()\n",
    "\n",
    "# Gets the input shape from the 128 x 64 Keras model\n",
    "input_details_2 = interpreter_2.get_input_details()\n",
    "output_details_2 = interpreter_2.get_output_details()\n",
    "input_shape_2 = input_details_2[0]['shape']\n",
    "\n",
    "# Loads 128 x 128 Keras model from H5 file\n",
    "interpreter_3 = tf.lite.Interpreter(model_path = \"~/Models/128_x_128_2D.tflite\")\n",
    "interpreter_3.allocate_tensors()\n",
    "\n",
    "# Gets the input shape from the 128 x 128 Keras model\n",
    "input_details_3 = interpreter_3.get_input_details()\n",
    "output_details_3 = interpreter_3.get_output_details()\n",
    "input_shape_3 = input_details_3[0]['shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Inference: A callback thread adds two-second samples of microphone data to an audio analysis queue; the main thread, an audio analysis thread, detects the presence of gunshot sounds in samples retrieved from the audio analysis queue; and an SMS alert thread dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS Alert Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SMS alert thread will run indefinitely\n",
    "def send_sms_alert():\n",
    "    \n",
    "    if SMS_ALERTS_ENABLED:\n",
    "        \n",
    "        # Configuring the Modem Connection\n",
    "        modem_port = '/dev/ttyUSB0'\n",
    "        modem_baudrate = 115200\n",
    "        modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "        # Establishing a Connection to the SMS Modem\n",
    "        logger.debug(\"Initializing connection to modem...\")\n",
    "        modem = GsmModem(modem_port, modem_baudrate)\n",
    "        modem.smsTextMode = False\n",
    "        \n",
    "        if modem_sim_pin:\n",
    "            modem.connect(modem_sim_pin)\n",
    "        else:\n",
    "            modem.connect()\n",
    "    \n",
    "        # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "        while True:\n",
    "            sms_alert_status = sms_alert_queue.get()\n",
    "            sms_alert_timestamp = sms_alert_queue.get()\n",
    "            if sms_alert_status == \"Gunshot Detected\":\n",
    "                try:\n",
    "                    # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                    modem.waitForNetworkCoverage(timeout = NETWORK_COVERAGE_TIMEOUT)\n",
    "                    for number in DESIGNATED_ALERT_RECIPIENTS:\n",
    "                        modem.sendSms(number, ALERT_MESSAGE + sms_alert_timestamp)\n",
    "                    logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "                except:\n",
    "                    logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                    pass\n",
    "                finally:\n",
    "                    logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            sms_alert_status = sms_alert_queue.get()\n",
    "            sms_alert_timestamp = sms_alert_queue.get()\n",
    "            if sms_alert_status == \"Gunshot Detected\":\n",
    "                logger.debug(ALERT_MESSAGE + sms_alert_timestamp)\n",
    "\n",
    "\n",
    "# Starts the SMS alert thread\n",
    "sms_alert_thread = Thread(target = send_sms_alert)\n",
    "sms_alert_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"float32\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    if len(sound_data) >= 88200:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        current_time = time.ctime(time.time())\n",
    "        audio_analysis_queue.put(current_time)\n",
    "        sound_data = np.zeros(0, dtype = \"float32\")\n",
    "    return sound_buffer, pyaudio.paContinue\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "stream = pa.open(format = AUDIO_FORMAT,\n",
    "                 rate = AUDIO_RATE,\n",
    "                 channels = NUMBER_OF_AUDIO_CHANNELS,\n",
    "                 input_device_index = AUDIO_DEVICE_INDEX,\n",
    "                 frames_per_buffer = NUMBER_OF_FRAMES_PER_BUFFER,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "logger.debug(\"--- Listening to Audio Stream ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Analysis Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Starts the scheduler for clearing the primary log file\n",
    "schedule.every().day.at(SCHEDULED_LOG_FILE_TRUNCATION_TIME).do(clear_log_file)\n",
    "\n",
    "# This thread will run indefinitely\n",
    "while True:\n",
    "    # Refreshes the scheduler\n",
    "    schedule.run_pending()\n",
    "    \n",
    "    # Gets a sample and its timestamp from the audio analysis queue\n",
    "    microphone_data = np.array(audio_analysis_queue.get(), dtype = \"float32\")\n",
    "    time_of_sample_occurrence = audio_analysis_queue.get()\n",
    "    \n",
    "    # Cleans up the global NumPy audio data source\n",
    "    sound_data = np.zeros(0, dtype = \"float32\")\n",
    "        \n",
    "    # Finds the current sample's maximum frequency value\n",
    "    maximum_frequency_value = np.max(microphone_data)\n",
    "        \n",
    "    # Determines whether a given sample potentially contains a gunshot\n",
    "    if maximum_frequency_value >= AUDIO_VOLUME_THRESHOLD:\n",
    "        \n",
    "        # Displays the current sample's maximum frequency value\n",
    "        logger.debug(\"The maximum frequency value of a given sample before processing: \" + str(maximum_frequency_value))\n",
    "        \n",
    "        # Post-processes the microphone data\n",
    "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
    "        if NOISE_REDUCTION_ENABLED and noise_sample_captured:\n",
    "                # Acts as a substitute for normalization\n",
    "                modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_sample)\n",
    "                number_of_missing_hertz = 44100 - len(modified_microphone_data)\n",
    "                modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_hertz)], dtype = \"float32\")\n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "\n",
    "        # Passes an audio sample of an appropriate format into the model for inference\n",
    "        processed_data_1 = modified_microphone_data\n",
    "        processed_data_1 = processed_data_1.reshape(input_shape_1)\n",
    "\n",
    "        HOP_LENGTH = 345 * 2\n",
    "        processed_data_2 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
    "        processed_data_2 = processed_data_2.reshape(input_shape_2)\n",
    "            \n",
    "        HOP_LENGTH = 345\n",
    "        processed_data_3 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
    "        processed_data_3 = processed_data_3.reshape(input_shape_3)\n",
    "\n",
    "        # Performs inference with the instantiated TensorFlow Lite models\n",
    "        interpreter_1.set_tensor(input_details_1[0]['index'], processed_data_1)\n",
    "        interpreter_1.invoke()\n",
    "        probabilities_1 = interpreter_1.get_tensor(output_details_1[0]['index'])\n",
    "        \n",
    "        interpreter_2.set_tensor(input_details_2[0]['index'], processed_data_2)\n",
    "        interpreter_2.invoke()\n",
    "        probabilities_2 = interpreter_2.get_tensor(output_details_2[0]['index'])\n",
    "        \n",
    "        interpreter_3.set_tensor(input_details_3[0]['index'], processed_data_3)\n",
    "        interpreter_3.invoke()\n",
    "        probabilities_3 = interpreter_3.get_tensor(output_details_3[0]['index'])\n",
    "        \n",
    "        logger.debug(\"The 44100 x 1 model-predicted probability values: \" + str(probabilities_1[0]))\n",
    "        logger.debug(\"The 128 x 64 model-predicted probability values: \" + str(probabilities_2[0]))\n",
    "        logger.debug(\"The 128 x 128 model-predicted probability values: \" + str(probabilities_3[0]))\n",
    "        logger.debug(\"The 44100 x 1 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_1[:, 0])[0])\n",
    "        logger.debug(\"The 128 x 64 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_2[:, 0])[0])\n",
    "        logger.debug(\"The 128 x 128 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_3[:, 0])[0])\n",
    "        \n",
    "        # Records which models, if any, identified a gunshot\n",
    "        model_1_activated = probabilities_1[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "        model_2_activated = probabilities_2[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "        model_3_activated = probabilities_3[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
    "\n",
    "        # Majority Rules: Determines if a gunshot sound was detected by a majority of the models\n",
    "        if model_1_activated and model_2_activated or model_2_activated and model_3_activated or model_1_activated and model_3_activated:\n",
    "                \n",
    "            # Sends out an SMS alert\n",
    "            sms_alert_queue.put(\"Gunshot Detected\")\n",
    "\n",
    "            # Sends out the time a given sample was heard\n",
    "            sms_alert_queue.put(time_of_sample_occurrence)\n",
    "\n",
    "            # Makes a WAV file of the gunshot sample\n",
    "            create_gunshot_wav_file(modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
    "\n",
    "            # Increments the counter for gunshot sound file names\n",
    "            gunshot_sound_counter += 1\n",
    "    \n",
    "    # Allows us to capture two seconds of background noise from the microphone for noise reduction\n",
    "    elif NOISE_REDUCTION_ENABLED and not noise_sample_captured:\n",
    "        noise_sample = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
    "        noise_sample = noise_sample[:44100]\n",
    "        noise_sample_captured = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
